# Using my zsh alias for ls (exa --icons --color=always) makes me happy
del aliases['ls']

source-zsh "echo loading xonsh foreign shell"
xontrib load coconut fish_completer fzf-widgets readable-traceback vox whole_word_jumping zoxide

# Xonsh envvars
$AUTO_CD = True
$AUTO_SUGGEST = True
$AUTO_SUGGEST_IN_COMPLETIONS = True
$XONSH_AUTOPAIR = True
$XONSH_COPY_ON_DELETE = True
$XONSH_CTRL_BKSP_DELETION = True
$XONSH_SHOW_TRACEBACK = True
$VI_MODE = True

$fzf_history_binding = 'c-r'
$fzf_ssh_binding = 'c-x'
$fzf_file_binding = 'c-f'
$fzf_find_command = 'fd --type f --hidden --follow --exclude .git'
$fzf_dir_binding = 'c-g'
$fzf_find_dirs_command = 'fd --type d --hidden --follow --exclude .git'

from argparse import ArgumentParser
from datetime import datetime as dt
from docopt import docopt
import json
from pathlib import Path
import re
from typing import Iterable
from zipfile import ZipFile

from intcli.api.intclient import IntegrateClient
from intcli.config import Config as IcliConfig
from intcli.cli.util import print_with_pager, ForceOption
import icli_render
from rich import inspect
from rich.console import Console
from rich.text import Text
from rich.theme import Theme
from rich.tree import Tree
import rich_tables.table
import yaml

rcon = Console(
    theme=Theme(icli_render.THEME_DICT),
)

def rp(*args, **kwargs):
    """Print to the rich console."""
    try:
        rcon.print(*args, **kwargs)
    except Exception:
        rcon.print_exception(show_locals=True)

def jls(jstring: str):
    """Load a JSON string."""
    return json.loads(jstring)

def jlf(jfile: str | Path):
    """Load a JSON file."""
    if isinstance(jfile, str):
        jfile = Path(jfile)
    with jfile.open() as f:
        return json.load(f)

def jds(data: dict):
    """Dump a JSON string."""
    return json.dumps(data)

def jdf(data: dict, jfile: str | Path):
    """Dump a JSON file."""
    if isinstance(jfile, str):
        jfile = Path(jfile)
    with jfile.open('w') as f:
        json.dump(data, f)

def rinse(obj):
    """Dump an object through rich's inspect."""
    with rcon.pager(styles=True):
        inspect(obj, console=rcon)

def _tree_recursive(data):
    """Build a rich tree from a nested data structure."""
    if type(data) in (str, int, float, bool):
        return Text(str(data))
    elif isinstance(data, dict):
        for k, v in data.items():
            tree = Tree(Text(k, style='bold blue'))
            if isinstance(v, Iterable):
                for _v in v:
                    tree.add(_tree_recursive(_v))
            else:
                tree.add(_tree_recursive(v))
        return tree
    elif isinstance(data, Iterable):
        tree = Tree('List')
        for v in data:
            tree.add(_tree_recursive(v))
        return tree
    else:
        raise ValueError(f'Cannot build tree from {data}')

def _ls_zip(args):
    parser = ArgumentParser()
    parser.add_argument('zipfile', type=str, help='zipfile to list')
    parser.add_argument('-j', '--json', action='store_true', help='output json')

    ns = parser.parse_args(args)
    zipfile = ns.zipfile

    with ZipFile(zipfile, 'r') as zf:
        ls = {
            'name': zipfile,
            'size': sum(zi.file_size for zi in zf.infolist()),
            'modified': str(dt(*max(zi.date_time for zi in zf.infolist()))),
            'contents': []
        }
        info = zf.infolist()
        ls['contents'].extend([{
            'name': zi.filename,
            'size': zi.file_size,
            'modified': str(dt(*zi.date_time))
        } for zi in info])


    if ns.json:
        print(json.dumps(ls))
    else:
        ripr(ls)


def ripr(data, json=False):
    """Render a fancy rich table from an arbitrary data structure."""
    if json:
        rcon.print_json(data=data)
    else:
        for ret in rich_tables.table.draw_data(data):
            rp(ret)


def _init_icli(args, stdin=None):
    """(Re)initialize the intcli config, either from a file or stdin.

    Takes up to one argument, a file to read the config from. If no argument is
    given, reads from stdin. If no argument is given and stdin is empty, reads
    from ~/.intcli/config.yaml.

    Usage:
        init_icli
        init_icli [FILE]
        init_icli < FILE
    """
    from intcli.config import Config as IcliConfig
    from intcli.api.intclient import IntegrateClient
    if stdin is not None:
        icli_config = IcliConfig.from_yaml(stdin)
    elif len(args) > 0:
        icli_config = IcliConfig.from_yaml(args[0])
    else:
        icli_config = IcliConfig.from_yaml(p'~/.config/intcli/config.yaml')
    return IntegrateClient.from_config(icli_config)


icli = _init_icli([])


def _dg_logparse(args, stdin=None):
    patt = re.compile(r'''(?xs)
(?P<Timestamp>
    (?:\d{4}(?:-\d{2}){2}) # date
    [ T] # date/time separator
    \d{2}(?::\d{2}){2}(?:[.,]\d{1,9})? # time
    (?:Z|[-+]\d{2}(?::\d{2})?)? # timezone
)\s+
(?P<Task>\[.*?\])\s+
(?P<Level>[A-Z]+)\s+
(?P<Message>
    .*?-\s((?=From\s1Integrate:))?(?(5)(?:)|(?:.*$))
)
(?P<ErrorMsg>(?(5).*))
    ''')
    parser = ArgumentParser()
    parser.add_argument('logfile', type=str, help='logfile to parse', default=None)
    ns = parser.parse_args(args)
    c = Console()

    if ns.logfile is None:
        if stdin is None:
            raise ValueError('No logfile specified and no stdin')
        else:
            log_str = stdin
    else:
        with open(ns.logfile, 'r') as f:
            log_str = f.read()
    
    log_lines = re.split(r'\n(?=\d{4}-\d{2}-\d{2})', log_str)
    
    log, err = [], {}

    for line in log_lines:
        m = patt.match(line).groupdict()
        if m['ErrorMsg']:
            err.update({f'Error {len(err.items()) + 1}': m['ErrorMsg']})
        log.append({
            'Timestamp': m['Timestamp'],
            'Task': m['Task'],
            'Level': m['Level'],
            'Message': m['Message']
        })

    with rcon.pager(styles=True):
        rcon.print(rich_tables.generic.flexitable({'1Data Gateway Log': log}),
                rich_tables.generic.flexitable(err))


def render_action_rule(entity, name=None):
    try:
        print_with_pager(icli_render.rule(entity, name), rcon, ForceOption.ALWAYS)
    except Exception:
        with rcon.pager(styles=True):
            rcon.print_exception(show_locals=True)

def _icli_fzf(args):
    """Fuzzy find a 1Integrate resource URL."""
    try:
        icli.get('grid') # Check that we can connect to the server.
    except Exception:
        rcon.print_exception(show_locals=True)
        raise SystemExit(1)
    res_types = ['rules', 'actions', 'datastores', 'actionmaps', 'sessions']
    res_type = $(echo @('\n'.join(res_types)) | fzf --prompt='Resource Type: ').strip()
    if not res_type:
        raise ValueError('No resource type selected.')
    return $(intcli raw ls @(res_type) | fzf --prompt='Resource: ').strip()

def _remote_render_actionrule(args):
    """Render an Action or Rule from a running 1Integrate instance."""
    target = _icli_fzf([])
    name = Path(target).name
    if not target:
        return
    render_action_rule(icli.get(target), name)

def _local_render_actionrule(args):
    """Render an Action or Rule from a local file."""
    target = Path(
        $(fd . -e '.action' -e '.rule' | fzf --prompt='File: ').strip()
    )
    if not target or target.is_dir():
        rcon.print('No file selected.')
        return
    elif not (target.suffix == '.action' or target.suffix == '.rule'):
        rcon.print('Cannot render file: not an Action or Rule.')
        return
    data = json.loads(target.read_text())
    name = target.name
    render_action_rule(data, name)

def _isp(args):
    """Perform a sync with the detected or specified version of the sync tool.

    Usage:
        isp [-dv VERSION] [--] ARGS...

    Arguments:
        args        Arguments to pass to the sync tool.

    Options:
        -d, --debug             Enable debug output.
        -v, --version VERSION   Version of the sync tool to use. If not specified, tries
                                to detect the version from the configured 1Integrate instance.
    """
    parsed_args = docopt(_isp.__doc__, argv=args)
    if parsed_args['--debug']:
        rcon.print_json(json.dumps(parsed_args, indent=2))
    if parsed_args['--version'] is None:
        version = icli.version['version']
    else:
        version = parsed_args['--version']

    with ${...}.swap(INT_TARGET_VERSION=version):
        isync @(parsed_args['ARGS'])


def _sync_ng911(args):
    """Sync the entire NG911 package to the configured 1Integrate instance.
    
    The NG911 package is hosted in three (four, if the Dashboard is included)
    separate repositories. This command will checkout and pull the latest
    development branch from each repository, and then sync the entire package
    to the configured 1Integrate instance.

    Sync will use the sync.properties file in the NG911 package ruleset
    directory as the baseline for instance url and authentication. Includes and
    excludes for each package are specified in a YAML config file. Depends on
    `isync` and `isp`, 1Integrate sync tool wrappers written for Xonsh.

    TODO: Pull this out into a dedicated Xonsh script.
    TODO: Pull `isp`'s version detection into isync so this depends only on isync.

    Usage:
        sync_ng911 [-dc FILE -p FILE]

    Options:
        -c, --config FILE   Path to the sync config file. [default: $INT_REPO_DIR/sync_configs/ng911.yaml]
        -d, --dashboard     Include the Dashboard repository in the sync.
        -p, --props FILE    Path to the sync.properties file. [default: $INT_REPO_DIR/con_saas_ng911/Ruleset/sync.properties]
    """
    parsed_args = docopt(_sync_ng911.__doc__, argv=args)
    
    # Setting default config files requires some extra work.
    if parsed_args['--config'] == '$INT_REPO_DIR/sync_configs/ng911.yaml':
        sync_config_file = pf'{$INT_REPO_DIR}/sync_configs/ng911.yaml'
    else:
        sync_config_file = Path(parsed_args['--config'])

    if parsed_args['--props'] == '$INT_REPO_DIR/con_saas_ng911/Ruleset/sync.properties':
        sync_props_file = pf'{$INT_REPO_DIR}/con_saas_ng911/Ruleset/sync.properties'
    else:
        sync_props_file = Path(parsed_args['--props'])

    # Actually load the config files.
    if sync_config_file.exists():
        configs = yaml.safe_load(sync_config_file.read_text())
    else:
        rcon.print(Text.assemble(
            Text('ERROR', style='bold red'),
            Text(': No sync config file found at '),
            Text(sync_config_file, style='bold')
        ))
        return 1
    if sync_props_file.exists():
        sync_props_parser = re.compile(r'(?P<key>[^=]+)=(?P<value>.+)')
        sync_props = {}
        for line in sync_props_file.read_text().splitlines():
            match = sync_props_parser.match(line)
            if match:
                sync_props[match.group('key')] = match.group('value')
    else:
        rcon.print(Text.assemble(
            Text('ERROR', style='bold red'),
            Text(': No sync.properties file found at '),
            Text(sync_props_file, style='bold')
        ))
        return 1

    # FIXME: For some reason, trying to sync ng911 breaks with a cataclysmic
    # "Unable to delete"-type error. I don't have time to debug this right now.
    repos = ['con_geom_essentials', 'con_network_essentials'] #, 'con_saas_ng911']
    if parsed_args['--dashboard']:
        repos.append('con_saas_dashboard')

    # Checkout and pull the latest development branch from each repository.
    for repo in repos:
        curr_dir = $(pwd).strip()
        $[cd @(f'{$INT_REPO_DIR}/{repo}')]
        # Record the current branch and stash any changes.
        configs[repo]['current_branch'] = $(git rev-parse --abbrev-ref HEAD).strip()
        if !(git diff --quiet):
            configs[repo]['stashed'] = False
            rcon.print(Text.assemble(
                Text('INFO', style='bold blue'),
                ': No changes to stash for ', Text(repo, style='bold'),
                ' on branch ',
                Text(configs[repo]['current_branch'], style='bold'),
            ))
        else:
            rcon.print(Text.assemble(
                Text('INFO', style='bold blue'),
                f': Stashing changes for ', Text(repo, style='bold'),
                ' on branch ',
                Text(configs[repo]['current_branch'], style='bold'),
            ))
            configs[repo]['stashed'] = True
            $[git stash]
        # Checkout the development branch
        if configs[repo]['current_branch'] == 'development':
            rcon.print(Text.assemble(
                Text('INFO', style='bold blue'),
                ': Already on development branch for ', Text(repo, style='bold'),
            ))
        else:
            rcon.print(Text.assemble(
                Text('INFO', style='bold blue'),
                f': Checking out development branch for ', Text(repo, style='bold'),
            ))
            $[git checkout development]
        # Pull the latest changes
        if !(git diff --quiet):
            rcon.print(Text.assemble(
                Text('INFO', style='bold blue'),
                f': No changes to pull for ', Text(repo, style='bold'),
            ))
        else:
            rcon.print(Text.assemble(
                Text('INFO', style='bold blue'),
                f': Pulling latest changes for ', Text(repo, style='bold'),
            ))
            $[git pull]

        # Run the sync for each repository.
        json_file = pf'{$INT_REPO_DIR}/sync_configs/sync_{repo}.json'.expanduser()
        isp_command = [
            '--',
            '-j', '-f', str(json_file),
            'push',
            './',
            '--',
            f'-url={sync_props["url"]}',
            f'-username={sync_props["username"]}',
            f'-password={sync_props["password"]}',
            f'-folders="{",".join(configs[repo]["folders"])}"',
            f'-exclude="{",".join(configs[repo]["exclude"])}"',
        ]
        _isp(isp_command)

        # TODO: Restore the original branch and stash for each repository.
        if not configs[repo]['current_branch'] == 'development':
            rcon.print(Text.assemble(
                Text('INFO', style='bold blue'),
                f': Checking out original branch for ', Text(repo, style='bold'),
            ))
            $[git checkout @(configs[repo]['current_branch'])]
        if configs[repo]['stashed']:
            rcon.print(Text.assemble(
                Text('INFO', style='bold blue'),
                f': Popping stash for ', Text(repo, style='bold'),
            ))
            $[git stash pop]

        # Return to the original directory.
        $[cd @(curr_dir)]

    # TODO: Gee, wouldn't it be nice if we got summarized results here?

aliases |= {
    'bap': 'bat --paging=always',
    'lr': 'tre',
    'lz': _ls_zip,
    'ric': ['python', '-m', 'rich_tables.table'],
    'init_icli': lambda a, s=None: _init_icli(a, s),
    'dgpl': _dg_logparse,
    'isp': _isp,
    'sync-ng911': _sync_ng911,
    'mofo': 'moar --follow',
    'icfz': _icli_fzf,
    'rarr': _remote_render_actionrule,
    'larr': _local_render_actionrule,
}

execx($(starship init xonsh))

# Local Variables:
# mode: xonsh
# End:
